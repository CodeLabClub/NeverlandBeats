{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **灯光捕捉（TracktheLight)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Demo 视频**\n",
    "\n",
    "摄像头根据颜色识别捕捉灯棒的移动，当灯棒从摄像头视野范围内消失后通过 Adapter 向 Scratch 发送消息，启动玫瑰窗的转动。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"video/demo3_tracktheLight.mp4\" controls  width=\"800\"  height=\"600\">\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import IPython.display as ipd\n",
    "\n",
    "ipd.Video('video/demo3_tracktheLight.mp4', width=800, height=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</br>\n",
    "\n",
    "## **Demo 代码**\n",
    "\n",
    "**视频中的示例项目主要包括两部分：**\n",
    "\n",
    "1. 使用 OpenCV 通过颜色识别追踪灯棒（树莓派驱动的 ws281x 8X8 灯阵）\n",
    "\n",
    "   感谢作者 Adrian Rosebroc！机器视觉部分的代码参考这篇[教程](https://www.pyimagesearch.com/2015/09/14/ball-tracking-with-opencv/)\n",
    "\n",
    "2. 灯棒移出摄像头捕捉范围时通过 Adapter EIM 触发 Scratch 项目中的玫瑰窗转动，项目[在此](https://create.codelab.club/projects/13195/)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "from imutils.video import VideoStream         # https://github.com/jrosebr1/imutils\n",
    "import numpy as np\n",
    "import imutils\n",
    "import time\n",
    "import cv2\n",
    "from codelab_adapter_client import AdapterNode\n",
    "\n",
    "\n",
    "# Adapter EIM Node 初始化\n",
    "class MyNode(AdapterNode):\n",
    "    NODE_ID = \"eim/rose_window\"    # 这个 ID 名（即 \"eim/\"后面的部分自己定义，配套 Scratch 项目中使用的接收和发送 EIM 消息的积木内要写与此一致的名字\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "    def send_data(self, content):\n",
    "        message = self.message_template()\n",
    "        message[\"payload\"][\"content\"] = content\n",
    "        self.publish(message)\n",
    "\n",
    "\n",
    "node = MyNode()\n",
    "node.receive_loop_as_thread()\n",
    "time.sleep(0.1)\n",
    "\n",
    "\n",
    "# 因为是通过颜色追踪物体，这里需要确定被识别颜色的范围（HSV），H 0-179， S 和 V 0-255\n",
    "redLower = (0, 0, 179)\n",
    "redUpper = (179, 255, 255)\n",
    "\n",
    "#定义用来存放被追踪物体轨迹位置的列表最长多少\n",
    "pts = deque(maxlen=128) \n",
    "\n",
    "# 启动摄像头\n",
    "vs = VideoStream(src=0).start()\n",
    "time.sleep(2.0)\n",
    "\n",
    "\n",
    "while True:\n",
    "\n",
    "    frame = vs.read()\n",
    "    frame = cv2.flip( frame, 1 ) \n",
    "    frame = imutils.resize(frame, width=800)\n",
    "    blurred = cv2.GaussianBlur(frame,(11, 11), 0)\n",
    "    hsv = cv2.cvtColor(blurred, cv2.COLOR_BGR2HSV)   \n",
    "    mask = cv2.inRange(hsv, redLower, redUpper)\n",
    "    # 关于 erode 和 dilate，参看文档解释\n",
    "    # erode 磨损前景（白色光亮区域）的轮廓部分，黑暗背景变大\n",
    "    # dilate 相反使前景光亮区域更大\n",
    "    # 通常都是先 erode，去掉前景周围白色微小 noise，然后 dilate 使前景损失掉的再补回来\n",
    "    # https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_imgproc/py_morphological_ops/py_morphological_ops.html\n",
    "    # 作者解释说这里是为了去掉 mask 中那些小的光点\n",
    "    mask = cv2.erode(mask, None, iterations=2)\n",
    "    mask = cv2.dilate(mask, None, iterations=2)       \n",
    "    cnts = cv2.findContours(mask.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = imutils.grab_contours(cnts)\n",
    "    center = None\n",
    "        \n",
    "        \n",
    "    if len(cnts)>0:\n",
    "        c = max(cnts, key=cv2.contourArea)\n",
    "        ((x,y), radius) = cv2.minEnclosingCircle(c)\n",
    "        M = cv2.moments(c)\n",
    "        center = (int(M[\"m10\"] / M[\"m00\"]), int(M[\"m01\"] / M[\"m00\"]))\n",
    "            \n",
    "        if radius > 10:\n",
    "            cv2.circle(frame, (int(x), int(y)), int(radius), (0, 255, 255), 2)\n",
    "            cv2.circle(frame, center, 5, (0, 0, 255), -1)\n",
    "\n",
    "            \n",
    "            \n",
    "    pts.appendleft(center)\n",
    "        \n",
    "    for i in range(1, len(pts)):\n",
    "        if pts[i - 1] is None or pts[i] is None:\n",
    "            continue           \n",
    "        thickness = int(np.sqrt(64/ float(i + 1))* 2.5)\n",
    "        cv2.line(frame, pts[i - 1], pts[i], (0, 0, 255), thickness)\n",
    "        \n",
    "    cv2.imshow('Frame', frame)\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "        \n",
    "    if key == ord(\"q\"):\n",
    "        break\n",
    "        vs.stop()\n",
    "        cv2.destroyAllWindows()\n",
    "                                    \n",
    "                                    \n",
    "    if len(cnts)==0:\n",
    "        node.send_data(\"go\")\n",
    "        vs.stop()\n",
    "        cv2.destroyAllWindows()\n",
    "        break\n",
    "                                  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</br>\n",
    "\n",
    "## **附：确定要识别追踪物体的颜色范围（color range）**\n",
    "\n",
    "如上面 Demo 所示，如果使用颜色识别追踪物体，需要确定物体的颜色范围，运行下方代码，就可以非常方便的拿到 HSV 取值范围。**感谢作者 Praveen！具体见这篇[文章](https://medium.com/programming-fever/how-to-find-hsv-range-of-an-object-for-computer-vision-applications-254a8eb039fc)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding hsv range of target object(pen)\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# A required callback method that goes into the trackbar function.\n",
    "def nothing(x):\n",
    "    pass\n",
    "\n",
    "# Initializing the webcam feed.\n",
    "# 将 VideoCapture 的第 3 个（从 0 算起）特性（共 0-18 19 个特性），即 frame_width，设为 1280\n",
    "# 同上，将 frame_height 设为 720\n",
    "# 关于 cap.set()和 cap.get() \n",
    "# 参看文档：https://docs.opencv.org/2.4/modules/highgui/doc/reading_and_writing_images_and_video.html#videocapture-get\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(3,1280)   \n",
    "cap.set(4,720)    \n",
    "\n",
    "# Create a window named trackbars.\n",
    "cv2.namedWindow(\"Trackbars\")\n",
    "\n",
    "# Now create 6 trackbars that will control the lower and upper range of \n",
    "# H,S and V channels. The Arguments are like this: Name of trackbar, \n",
    "# window name, range,callback function. For Hue the range is 0-179 and\n",
    "# for S,V its 0-255.\n",
    "cv2.createTrackbar(\"L - H\", \"Trackbars\", 0, 179, nothing)\n",
    "cv2.createTrackbar(\"L - S\", \"Trackbars\", 0, 255, nothing)\n",
    "cv2.createTrackbar(\"L - V\", \"Trackbars\", 0, 255, nothing)\n",
    "cv2.createTrackbar(\"U - H\", \"Trackbars\", 179, 179, nothing)\n",
    "cv2.createTrackbar(\"U - S\", \"Trackbars\", 255, 255, nothing)\n",
    "cv2.createTrackbar(\"U - V\", \"Trackbars\", 255, 255, nothing)\n",
    " \n",
    "while True:\n",
    "    \n",
    "    # Start reading the webcam feed frame by frame.\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "        \n",
    "    # Flip the frame horizontally (Not required)\n",
    "    frame = cv2.flip( frame, 1 ) \n",
    "    \n",
    "    # Convert the BGR image to HSV image.\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    # Get the new values of the trackbar in real time as the user changes \n",
    "    # them\n",
    "    l_h = cv2.getTrackbarPos(\"L - H\", \"Trackbars\")\n",
    "    l_s = cv2.getTrackbarPos(\"L - S\", \"Trackbars\")\n",
    "    l_v = cv2.getTrackbarPos(\"L - V\", \"Trackbars\")\n",
    "    u_h = cv2.getTrackbarPos(\"U - H\", \"Trackbars\")\n",
    "    u_s = cv2.getTrackbarPos(\"U - S\", \"Trackbars\")\n",
    "    u_v = cv2.getTrackbarPos(\"U - V\", \"Trackbars\")\n",
    " \n",
    "    # Set the lower and upper HSV range according to the value selected\n",
    "    # by the trackbar\n",
    "    lower_range = np.array([l_h, l_s, l_v])\n",
    "    upper_range = np.array([u_h, u_s, u_v])\n",
    "    \n",
    "    # Filter the image and get the binary mask, where white represents \n",
    "    # your target color\n",
    "    mask = cv2.inRange(hsv, lower_range, upper_range)\n",
    " \n",
    "    # You can also visualize the real part of the target color (Optional)\n",
    "    res = cv2.bitwise_and(frame, frame, mask=mask)\n",
    "    \n",
    "    # Converting the binary mask to 3 channel image, this is just so \n",
    "    # we can stack it with the others\n",
    "    mask_3 = cv2.cvtColor(mask, cv2.COLOR_GRAY2BGR)\n",
    "    \n",
    "    # stack the mask, orginal frame and the filtered result\n",
    "    stacked = np.hstack((mask_3,frame,res))\n",
    "    \n",
    "    # Show this stacked frame at 40% of the size.\n",
    "    cv2.imshow('Trackbars',cv2.resize(stacked,None,fx=0.4,fy=0.4))\n",
    "    \n",
    "    # If the user presses ESC then exit the program\n",
    "    key = cv2.waitKey(1)\n",
    "    if key == 27:\n",
    "        break\n",
    "    \n",
    "    # If the user presses `s` then print this array.\n",
    "    if key == ord('s'):\n",
    "        \n",
    "        thearray = [[l_h,l_s,l_v],[u_h, u_s, u_v]]\n",
    "        print(thearray)\n",
    "        \n",
    "        # Also save this array as penval.npy\n",
    "        np.save('hsv_value',thearray)\n",
    "        break\n",
    "    \n",
    "# Release the camera & destroy the windows.    \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
